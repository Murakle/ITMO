{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "another-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.6 (v3.8.6:db455296be, Sep 23 2020, 13:31:39) \n",
      "[Clang 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "awful-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet5_model():\n",
    "    model = tf.keras.models.Sequential() \n",
    "    model.add(tf.keras.layers.Conv2D(8, 5, input_shape=(28, 28, 1), padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))  \n",
    "    model.add(tf.keras.layers.Conv2D(16, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))  \n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(120, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))# енто совт-арг-макс а не совт-макс, кажется\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tracked-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPCP_model():\n",
    "    model = tf.keras.models.Sequential() \n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, input_shape=(28, 28, 1), activation='relu'))  \n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))# енто совт-арг-макс а не совт-макс, кажется\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "blessed-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model(dropout=0.2):\n",
    "    model = tf.keras.models.Sequential() \n",
    "    model.add(tf.keras.layers.Conv2D(16, 3, input_shape=(28, 28, 1), padding='same', activation='relu'))  \n",
    "    model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'))  \n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))# енто совт-арг-макс а не совт-макс, кажется\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ranging-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    mnist_data = MNIST(path)\n",
    "    mnist_train_images, mnist_train_labels = mnist_data.load_training()\n",
    "    mnist_test_images, mnist_test_labels = mnist_data.load_testing()\n",
    "    x_train = np.array(mnist_train_images)\n",
    "    y_train = np.array(mnist_train_labels)\n",
    "    x_test = np.array(mnist_test_images)\n",
    "    y_test = np.array(mnist_test_labels)\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    x_train = tf.reshape(x_train, [60000, 28, 28, 1])\n",
    "    x_test = tf.reshape(x_test, [10000, 28, 28, 1])\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "impossible-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preapare data\n",
    "x_train, y_train, x_test, y_test = read_data('./data/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "casual-header",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 10, 10, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 1, 1000)        401000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 412,046\n",
      "Trainable params: 412,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "closing-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 14ms/step - loss: 0.3970 - accuracy: 0.8765\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0593 - accuracy: 0.9811\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 25s 14ms/step - loss: 0.0407 - accuracy: 0.9871\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0294 - accuracy: 0.9904\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 0.0254 - accuracy: 0.9916\n",
      "LeNet5 0.03099902719259262 0.9891999959945679\n"
     ]
    }
   ],
   "source": [
    "# Lenet5\n",
    "model = LeNet5_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, verbose=1)\n",
    "error, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"LeNet5\", error, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "legendary-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 51s 27ms/step - loss: 0.4255 - accuracy: 0.8632\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 45s 24ms/step - loss: 0.0695 - accuracy: 0.9771\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0437 - accuracy: 0.9870\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0333 - accuracy: 0.9892\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 55s 30ms/step - loss: 0.0230 - accuracy: 0.9928\n",
      "CPCP 0.03847016021609306 0.9896000027656555\n"
     ]
    }
   ],
   "source": [
    "model = CPCP_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, verbose=1)\n",
    "error, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"CPCP\", error, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "lovely-chancellor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 92s 47ms/step - loss: 0.3125 - accuracy: 0.9015\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0567 - accuracy: 0.9826\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 102s 55ms/step - loss: 0.0403 - accuracy: 0.9875\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 115s 62ms/step - loss: 0.0300 - accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 110s 59ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "vgg 0.020278984680771828 0.9940999746322632\n"
     ]
    }
   ],
   "source": [
    "model = vgg_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, verbose=1)\n",
    "error, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"vgg\", error, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "finite-graphic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9940999746322632 0.020278984680771828\n",
      "CM\n",
      " tf.Tensor(\n",
      "[[ 977    0    0    0    0    0    1    1    1    0]\n",
      " [   0 1134    1    0    0    0    0    0    0    0]\n",
      " [   1    0 1027    0    0    0    0    3    1    0]\n",
      " [   0    1    0 1007    0    1    0    0    1    0]\n",
      " [   0    0    0    0  974    0    0    1    1    6]\n",
      " [   1    0    0    6    0  883    1    0    0    1]\n",
      " [   3    3    0    0    3    1  947    0    1    0]\n",
      " [   0    3    0    0    0    1    0 1020    1    3]\n",
      " [   0    0    0    0    0    1    0    0  971    2]\n",
      " [   0    0    0    0    3    2    0    1    2 1001]], shape=(10, 10), dtype=int32)\n",
      "[[  10. 6651. 8382. 1748. 6651. 1748. 1621. 6597. 6651. 6597.]\n",
      " [7928.   14. 2018. 2266. 6572. 1527. 6572. 6572. 9071. 6572.]\n",
      " [2462.  659.   47. 1459.  646. 7249.  646. 4176. 8094. 8094.]\n",
      " [7233. 4443. 2927.   30. 2109. 4740. 2280. 2109. 5955. 3475.]\n",
      " [1178. 9669. 2836. 9669.   56. 9615.  160. 9669. 3534. 2130.]\n",
      " [3558. 1737. 3778. 2035. 1737.   23. 9729. 1299. 3778. 5997.]\n",
      " [3422. 2654. 9679. 9679. 3520. 1014.   11. 9698. 4571. 4571.]\n",
      " [3808. 6576. 9015.  726. 4007.  726.  726.   75. 3808.  846.]\n",
      " [1319. 6625.  582. 1878. 6625. 8408. 3062. 6625.  110. 3727.]\n",
      " [1247. 2387. 2129. 4284. 1232. 2939. 4823. 9692. 4761. 3760.]]\n"
     ]
    }
   ],
   "source": [
    "# VGG the best\n",
    "error, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(accuracy, error)\n",
    "k = 10\n",
    "predicted = model.predict(x_test)\n",
    "result = [0] * len(predicted) # result class\n",
    "sim = np.zeros((k, k)) \n",
    "maxr = np.ones((k, k)) * -1\n",
    "for j in range(len(predicted)):\n",
    "    res = predicted[j] # 10\n",
    "    for i in range(len(res)):\n",
    "        if res[i] > res[result[j]]:\n",
    "            result[j] = i\n",
    "        if maxr[y_test[j], i] < res[i]:\n",
    "            maxr[y_test[j], i] = res[i]\n",
    "            sim[y_test[j], i] = j\n",
    "cm = tf.math.confusion_matrix(y_test, result)\n",
    "print(\"CM\\n\",cm)\n",
    "print(sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "outdoor-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.6582 - accuracy: 0.7600\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 72s 38ms/step - loss: 0.3230 - accuracy: 0.8813\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2631 - accuracy: 0.9039\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2363 - accuracy: 0.9124\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.2125 - accuracy: 0.9210\n",
      "vgg 0.2469007521867752 0.9126999974250793\n"
     ]
    }
   ],
   "source": [
    "# test on fashion_mnist\n",
    "x_train, y_train, x_test, y_test = read_data('./data/fashion-mnist')\n",
    "model = vgg_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, verbose=1)\n",
    "error, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"vgg\", error, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-spare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
